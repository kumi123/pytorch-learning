{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 PyTorch第一步\n",
    "\n",
    "PyTorch的简洁设计使得它入门很简单，在深入介绍PyTorch之前，本节将先介绍一些PyTorch的基础知识，使得读者能够对PyTorch有一个大致的了解，并能够用PyTorch搭建一个简单的神经网络。部分内容读者可能暂时不太理解，可先不予以深究，本书的第3章和第4章将会对此进行深入讲解。\n",
    "\n",
    "本节内容参考了PyTorch官方教程[^1]并做了相应的增删修改，使得内容更贴合新版本的PyTorch接口，同时也更适合新手快速入门。另外本书需要读者先掌握基础的Numpy使用，其他相关知识推荐读者参考CS231n的教程[^2]。\n",
    "\n",
    "[^1]: http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "[^2]: http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "Tensor是PyTorch中重要的数据结构，可认为是一个高维数组。它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）以及更高维的数组。Tensor和Numpy的ndarrays类似，但Tensor可以使用GPU进行加速。Tensor的使用和Numpy及Matlab的接口十分相似，下面通过几个例子来看看Tensor的基本使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T08:50:08.824902Z",
     "start_time": "2019-02-10T08:50:08.819888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from __future__ import print_function\n",
    "import torch as t\n",
    "t.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T08:51:03.625286Z",
     "start_time": "2019-02-10T08:51:03.617287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建 5x3 矩阵，只是分配了空间，未初始化\n",
    "x = t.Tensor(5, 3)#tensor是Torch之中的一个数据类型\n",
    "\n",
    "x = t.Tensor([[1,2],[3,4]])#类似于numpy之中的array\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:23:43.890509Z",
     "start_time": "2019-02-10T14:23:43.885517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.7220e-01, 5.0649e-01, 8.5444e-01],\n",
       "        [1.8370e-04, 6.4025e-01, 2.4625e-01],\n",
       "        [1.7869e-02, 1.8889e-01, 7.2948e-01],\n",
       "        [9.1755e-01, 5.1117e-01, 2.1851e-01],\n",
       "        [1.1147e-01, 3.3796e-01, 6.8282e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)  #这里是利用所谓的t来作为简写好不好\n",
    "x#0到1之间的的所谓均匀分布5航三列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:23:46.273900Z",
     "start_time": "2019-02-10T14:23:46.266904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size()) # 查看x的形状\n",
    "x.size()[1]\n",
    "x.size(1) # 查看列的个数, 两种写法等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Size` 是tuple对象的子类，因此它支持tuple的所有操作，如x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:23:48.528158Z",
     "start_time": "2019-02-10T14:23:48.505171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0825, 1.0945, 1.0405],\n",
       "        [0.1162, 1.0617, 0.7188],\n",
       "        [0.3256, 0.3387, 1.3398],\n",
       "        [1.7939, 0.6378, 0.6948],\n",
       "        [1.0341, 0.8821, 1.2690]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.rand(5, 3)\n",
    "# 加法的第一种写法\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:23:52.547145Z",
     "start_time": "2019-02-10T14:23:52.480166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0825, 1.0945, 1.0405],\n",
       "        [0.1162, 1.0617, 0.7188],\n",
       "        [0.3256, 0.3387, 1.3398],\n",
       "        [1.7939, 0.6378, 0.6948],\n",
       "        [1.0341, 0.8821, 1.2690]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第二种写法\n",
    "t.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:24:19.976376Z",
     "start_time": "2019-02-10T14:24:19.970362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0825, 1.0945, 1.0405],\n",
       "        [0.1162, 1.0617, 0.7188],\n",
       "        [0.3256, 0.3387, 1.3398],\n",
       "        [1.7939, 0.6378, 0.6948],\n",
       "        [1.0341, 0.8821, 1.2690]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第三种写法：指定加法结果的输出目标为result\n",
    "result = t.Tensor(5, 3) # 预先分配空间\n",
    "t.add(x, y, out=result) # 输入到result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:24:43.232260Z",
     "start_time": "2019-02-10T14:24:43.224264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初y\n",
      "tensor([[0.2103, 0.5880, 0.1861],\n",
      "        [0.1160, 0.4214, 0.4726],\n",
      "        [0.3077, 0.1498, 0.6103],\n",
      "        [0.8763, 0.1266, 0.4762],\n",
      "        [0.9226, 0.5441, 0.5861]])\n",
      "第一种加法，y的结果\n",
      "tensor([[0.2103, 0.5880, 0.1861],\n",
      "        [0.1160, 0.4214, 0.4726],\n",
      "        [0.3077, 0.1498, 0.6103],\n",
      "        [0.8763, 0.1266, 0.4762],\n",
      "        [0.9226, 0.5441, 0.5861]])\n",
      "第二种加法，y的结果\n",
      "tensor([[1.0825, 1.0945, 1.0405],\n",
      "        [0.1162, 1.0617, 0.7188],\n",
      "        [0.3256, 0.3387, 1.3398],\n",
      "        [1.7939, 0.6378, 0.6948],\n",
      "        [1.0341, 0.8821, 1.2690]])\n"
     ]
    }
   ],
   "source": [
    "print('最初y')\n",
    "print(y)\n",
    "\n",
    "print('第一种加法，y的结果')\n",
    "y.add(x) # 普通加法，不改变y的内容\n",
    "print(y)\n",
    "\n",
    "print('第二种加法，y的结果')\n",
    "y.add_(x) # inplace 加法，y变了\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，函数名后面带下划线**`_`** 的函数会修改Tensor本身。例如，`x.add_(y)`和`x.t_()`会改变 `x`，但`x.add(y)`和`x.t()`返回一个新的Tensor， 而`x`不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:25:49.851337Z",
     "start_time": "2019-02-10T14:25:49.846322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5065, 0.6403, 0.1889, 0.5112, 0.3380])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor的选取操作与Numpy类似\n",
    "x[:, 1]#第2列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor还支持很多操作，包括数学运算、线性代数、选择、切片等等，其接口设计与Numpy极为相似。更详细的使用方法，会在第三章系统讲解。\n",
    "\n",
    "Tensor和Numpy的数组之间的互操作非常容易且快速。对于Tensor不支持的操作，可以先转为Numpy数组处理，之后再转回Tensor。c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:31:20.149014Z",
     "start_time": "2019-02-10T14:31:20.143001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy() # Tensor -> Numpy转成array形式\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:33:29.555161Z",
     "start_time": "2019-02-10T14:33:29.397514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy->Tensor\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b.add_(1) # 以`_`结尾的函数会修改自身\n",
    "print(a)\n",
    "print(b) # Tensor和Numpy共享内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想获取某一个元素的值，可以使用`scalar.item`。 直接`tensor[idx]`得到的还是一个tensor: 一个0-dim 的tensor，一般称为scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = b[0]#tensor 的元素也是Tensor\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.size() #0-dim 一个scale便是tensor的一个元素，维度为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # 使用scalar.item()能从中取出python对象的数值，获取数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2]), tensor(2., dtype=torch.float64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.tensor([2]) # 注意和scalar的区别，说明这是一个只有一个元素的tensor\n",
    "tensor,scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.size(),scalar.size()#一个是0维 一个是1维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有一个元素的tensor也可以调用`tensor.item()`\n",
    "tensor.item(), scalar.item()#返回具体值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外在pytorch中还有一个和`np.array` 很类似的接口: `torch.tensor`, 二者的使用十分类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:39:41.271336Z",
     "start_time": "2019-02-10T14:39:41.249348Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor = t.tensor([3,4]) # 新建一个包含 3，4 两个元素的tensor，要明白是3和4而不是3行4列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:39:43.140339Z",
     "start_time": "2019-02-10T14:39:43.135330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = t.tensor(3)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:39:45.649216Z",
     "start_time": "2019-02-10T14:39:45.429810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\fastai\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), tensor([1111,    4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "old_tensor = tensor\n",
    "new_tensor = t.tensor(old_tensor)\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">需要注意的是，`t.tensor()`总是会进行数据拷贝，新tensor和原来的数据不再共享内存。所以如果你想共享内存的话，建议使用`torch.from_numpy()`或者`tensor.detach()`来新建一个tensor, 二者共享内存。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1111,     4]), tensor([ 1111,     4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = old_tensor.detach()\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor可通过`.cuda` 方法转为GPU的Tensor，从而享受GPU带来的加速运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在不支持CUDA的机器下，下一步还是在CPU上运行\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "z = x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还可以使用`tensor.cuda()` 的方式将tensor拷贝到gpu上，但是这种方式不太推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处可能发现GPU运算的速度并未提升太多，这是因为x和y太小且运算也较为简单，而且将数据从内存转移到显存还需要花费额外的开销。GPU的优势需在大规模数据和复杂运算下才能体现出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### autograd: 自动微分\n",
    "\n",
    "深度学习的算法本质上是通过反向传播求导数，而PyTorch的**`autograd`**模块则实现了此功能。在Tensor上的所有操作，autograd都能为它们自动提供微分，避免了手动计算导数的复杂过程。\n",
    " \n",
    "~~`autograd.Variable`是Autograd中的核心类，它简单封装了Tensor，并支持几乎所有Tensor有的操作。Tensor在被封装为Variable之后，可以调用它的`.backward`实现反向传播，自动计算所有梯度~~ ~~Variable的数据结构如图2-6所示。~~\n",
    "\n",
    "\n",
    "![图2-6:Variable的数据结构](imgs/autograd_Variable.svg)\n",
    "\n",
    "  *从0.4起, Variable 正式合并入Tensor, Variable 本来实现的自动微分功能，Tensor就能支持。读者还是可以使用Variable(tensor), 但是这个操作其实什么都没做。建议读者以后直接使用tensor*. \n",
    "  \n",
    "  要想使得Tensor使用autograd功能，只需要设置`tensor.requries_grad=True`. \n",
    "\n",
    "\n",
    "~~Variable主要包含三个属性。~~\n",
    "~~- `data`：保存Variable所包含的Tensor~~\n",
    "~~- `grad`：保存`data`对应的梯度，`grad`也是个Variable，而不是Tensor，它和`data`的形状一样。~~\n",
    "~~- `grad_fn`：指向一个`Function`对象，这个`Function`用来反向传播计算输入的梯度，具体细节会在下一章讲解。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:42:10.308252Z",
     "start_time": "2019-02-10T14:42:09.977402Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为tensor设置 requires_grad 标识，代表着需要求导数\n",
    "# pytorch 会自动调用autograd 记录操作\n",
    "x = t.ones(2, 2, requires_grad=True)\n",
    "#说明需要求倒数\n",
    "# 上一步等价于\n",
    "# x = t.ones(2,2)\n",
    "# x.requires_grad = True\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:42:18.853560Z",
     "start_time": "2019-02-10T14:42:18.631397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y#直接相加所有元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:48:00.677894Z",
     "start_time": "2019-02-10T14:48:00.673877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x2211c5b3080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:48:07.984010Z",
     "start_time": "2019-02-10T14:48:07.722661Z"
    }
   },
   "outputs": [],
   "source": [
    "y.backward() # 反向传播,计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:52:38.693361Z",
     "start_time": "2019-02-10T14:52:38.687364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = x.sum() = (x[0][0] + x[0][1] + x[1][0] + x[1][1])\n",
    "# 每个值的梯度都为1，为什么是1？\n",
    "x.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">注意：`grad`在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。为什么梯度是1？</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:48:53.795974Z",
     "start_time": "2019-02-10T14:48:53.789978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:48:56.205268Z",
     "start_time": "2019-02-10T14:48:56.199272Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad\n",
    "#意思便是这算是做完反向传播了，y.backward()，但是x.grad梯度是累加的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T14:49:06.571484Z",
     "start_time": "2019-02-10T14:49:06.550502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下划线结束的函数是inplace操作，会修改自身的值，就像add_\n",
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  神经网络\n",
    "\n",
    "Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，torch.nn是专门为神经网络设计的模块化接口。nn构建于 Autograd之上，可用来定义和运行神经网络。nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，调用forward(input)方法，可返回前向传播的结果。下面就以最早的卷积神经网络：LeNet为例，来看看如何用`nn.Module`实现。LeNet的网络结构如图2-7所示。\n",
    "\n",
    "![图2-7:LeNet网络结构](imgs/nn_lenet.png)\n",
    "\n",
    "这是一个基础的前向传播(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。\n",
    "\n",
    "#### 定义网络\n",
    "\n",
    "定义网络时，需要继承`nn.Module`，并实现它的forward方法，把网络中具有可学习参数的层放在构造函数`__init__`中。如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用`nn.functional`代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:07:35.327140Z",
     "start_time": "2019-02-10T15:07:35.315140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn#导入神经网络模块\n",
    "import torch.nn.functional as F#导入需要的函数分析\n",
    "#定义具体的网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        #上边的相当于必须要进行初始化的过程\n",
    "        # 下式等价于nn.Module.__init__(self)\n",
    "        super(Net, self).__init__()#初始化过程\n",
    "        #以上两句是必须要有的过程\n",
    "        # 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'5'表示卷积核为5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #定义卷积层，'1'表示输入图片为单通道黑白, '6'表示输出通道数，是6个filter\n",
    "        #，'5'表示卷积核为5*5\n",
    "        # 卷积层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #你想想第一个是6个filter，所以是6个通道数，这一个有16个filter\n",
    "        #下一层是16个通道\n",
    "        # 仿射层/全连接层，y = Wx + b\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) #展平了参数，因为是最后是16层，5x5代表着是filter大小\n",
    "        #120是代表全连接层第一个是120个神经元\n",
    "        self.fc2   = nn.Linear(120, 84)#第二层84个\n",
    "        self.fc3   = nn.Linear(84, 10)#第三层10个\n",
    "\n",
    "    def forward(self, x): #在这里是定义了前向西传播函数，输入是x\n",
    "        # 卷积 -> 激活 -> 池化 \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))#经过卷积层，池化的范围2*2\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) #经过第二个卷积层，池化范围为2*2\n",
    "        # reshape，‘-1’表示自适应\n",
    "        x = x.view(x.size()[0], -1) #在这里是将输出展开成一列\n",
    "        x = F.relu(self.fc1(x))#输入全连接层\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">只要在nn.Module的子类中定义了forward函数，backward函数就会自动被实现(利用`autograd`)。在`forward` 函数中可使用任何tensor支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。\n",
    "\n",
    "网络的可学习参数通过`net.parameters()`返回，`net.named_parameters`可同时返回可学习的参数及名称。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:08:27.075509Z",
     "start_time": "2019-02-10T15:08:27.071511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))#这里说明了学习的参数个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:09:34.796602Z",
     "start_time": "2019-02-10T15:09:34.790606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():#打印出网络里边的参数名称与大小\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward函数的输入和输出都是Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:17:39.158979Z",
     "start_time": "2019-02-10T15:17:39.151003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = t.randn(1, 1, 32, 32)#输入的是32*32*1的图片，1个例子\n",
    "out = net(input)#输出应该是10个\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:17:41.730153Z",
     "start_time": "2019-02-10T15:17:41.724175Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad() # 所有参数的梯度清零初始化\n",
    "out.backward(t.ones(1,10)) # 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 `input.unsqueeze(0)`将batch_size设为１。例如 `nn.Conv2d` 输入必须是4维的，形如$nSamples \\times nChannels \\times Height \\times Width$。可将nSample设为1，即$1 \\times nChannels \\times Height \\times Width$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数\n",
    "\n",
    "nn实现了神经网络中大多数的损失函数，例如nn.MSELoss用来计算均方误差，nn.CrossEntropyLoss用来计算交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:17:47.619582Z",
     "start_time": "2019-02-10T15:17:47.601580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Long for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-1769af32bbd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#转成一个列向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#定义误差函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#输入参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;31m# loss是个scalar，常数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2154\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2156\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "output = net(input)#输出\n",
    "target = t.arange(0,10).view(1,10) #转成一个列向量\n",
    "criterion = nn.MSELoss()#定义误差函数\n",
    "loss = criterion(output, target)#输入参数\n",
    "loss # loss是个scalar，常数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果对loss进行反向传播溯源(使用`gradfn`属性)，可看到它的计算图如下：\n",
    "\n",
    "```\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "      -> view -> linear -> relu -> linear -> relu -> linear \n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "```\n",
    "\n",
    "当调用`loss.backward()`时，该图会动态生成并自动微分，也即会自动计算图中参数(Parameter)的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:19:09.535943Z",
     "start_time": "2019-02-10T15:19:09.524930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播之前 conv1.bias的梯度\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9a405cf0a93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'反向传播之前 conv1.bias的梯度'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'反向传播之后 conv1.bias的梯度'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# 运行.backward，观察调用之前和调用之后的grad\n",
    "net.zero_grad() # 把net中所有可学习参数的梯度清零\n",
    "print('反向传播之前 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('反向传播之后 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：\n",
    "```\n",
    "weight = weight - learning_rate * gradient\n",
    "```\n",
    "\n",
    "手动实现如下：\n",
    "\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)# inplace 减法\n",
    "```\n",
    "\n",
    "`torch.optim`中实现了深度学习中绝大多数的优化方法，例如RMSProp、Adam、SGD等，更便于使用，因此大多数时候并不需要手动写上述代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:21:08.232410Z",
     "start_time": "2019-02-10T15:21:08.206446Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Long for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-76fb2d3a1cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# 计算损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2154\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2156\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "#新建一个优化器，指定要调整的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 在训练过程中\n",
    "# 先梯度清零(与net.zero_grad()效果一样)\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# 计算损失\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#反向传播\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "####  数据加载与预处理\n",
    "\n",
    "在深度学习中数据加载及预处理是非常复杂繁琐的，但PyTorch提供了一些可极大简化和加快数据处理流程的工具。同时，对于常用的数据集，PyTorch也提供了封装好的接口供用户快速调用，这些数据集主要保存在torchvison中。\n",
    "\n",
    "`torchvision`实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。\n",
    "\n",
    "\n",
    "### 小试牛刀：CIFAR-10分类\n",
    "\n",
    "下面我们来尝试实现对CIFAR-10数据集的分类，步骤如下: \n",
    "\n",
    "1. 使用torchvision加载并预处理CIFAR-10数据集\n",
    "2. 定义网络\n",
    "3. 定义损失函数和优化器\n",
    "4. 训练网络并更新网络参数\n",
    "5. 测试网络\n",
    "\n",
    "####   CIFAR-10数据加载及预处理\n",
    "\n",
    "CIFAR-10[^3]是一个常用的彩色图片数据集，它有10个类别: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。每张图片都是$3\\times32\\times32$，也即3-通道彩色图片，分辨率为$32\\times32$。\n",
    "\n",
    "[^3]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:21:30.723258Z",
     "start_time": "2019-02-10T15:21:29.098676Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:26:37.570855Z",
     "start_time": "2019-02-10T15:22:53.794858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/cy/tmp/data/cifar-10-python.tar.gz\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 第一次运行程序torchvision会自动下载CIFAR-10数据集，\n",
    "# 大约100M，需花费一定的时间，\n",
    "# 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "\n",
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='/home/cy/tmp/data/', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, #是指的每一次打乱bitch训练是随机取值\n",
    "                    num_workers=2)#默认用2便可以\n",
    "\n",
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    '/data/',\n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)\n",
    "\n",
    "testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "#以上是导入这个测试集合训练集\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:26:49.059629Z",
     "start_time": "2019-02-10T15:26:47.524741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x22120DC79B0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data, label) = trainset[100]#第101个图片\n",
    "print(classes[label])\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader是一个可迭代的对象，它将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:30:55.726687Z",
     "start_time": "2019-02-10T15:30:49.597340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      truck       plane        deer        deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x22122C0C5F8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next() # 返回4张图片及标签，利用批训练参数为4每一次来抽取4个\n",
    "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   定义网络\n",
    "\n",
    "拷贝上面的LeNet网络，修改self.conv1第一个参数为3通道，因CIFAR-10是3通道彩图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:32:24.287354Z",
     "start_time": "2019-02-10T15:32:24.274361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  定义损失函数和优化器(loss和optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:32:26.774415Z",
     "start_time": "2019-02-10T15:32:26.769418Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   训练网络\n",
    "\n",
    "所有网络的训练流程都是类似的，不断地执行如下流程：\n",
    "\n",
    "- 输入数据\n",
    "- 前向传播+反向传播\n",
    "- 更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:36:41.045124Z",
     "start_time": "2019-02-10T15:32:33.125841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.218\n",
      "[1,  4000] loss: 1.890\n",
      "[1,  6000] loss: 1.690\n",
      "[1,  8000] loss: 1.593\n",
      "[1, 10000] loss: 1.527\n",
      "[1, 12000] loss: 1.474\n",
      "[2,  2000] loss: 1.405\n",
      "[2,  4000] loss: 1.382\n",
      "[2,  6000] loss: 1.376\n",
      "[2,  8000] loss: 1.330\n",
      "[2, 10000] loss: 1.314\n",
      "[2, 12000] loss: 1.282\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "t.set_num_threads(8)\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # 输入数据\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处仅训练了2个epoch（遍历完一遍数据集称为一个epoch），来看看网络有没有效果。将测试图片输入到网络中，计算它的label，然后与实际的label进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际的label:       cat     ship     ship    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAABkCAIAAAAnqfEgAAA0bklEQVR4nO19WZMc6XXdqcysvbq6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\nEyf/z8r/Ab+8NWulkQjIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x7FFA9E5C8F28>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "print('实际的label: ', ' '.join(\\\n",
    "            '%08s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着计算网络预测的label："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果:   frog   car  ship  ship\n"
     ]
    }
   ],
   "source": [
    "# 计算图片在每个类别上的分数\n",
    "outputs = net(images)\n",
    "# 得分最高的那个类\n",
    "_, predicted = t.max(outputs.data, 1)\n",
    "\n",
    "print('预测结果: ', ' '.join('%5s'\\\n",
    "            % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经可以看出效果，准确率50%，但这只是一部分的图片，再来看看在整个测试集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试集中的准确率为: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "\n",
    "\n",
    "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "with t.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = t.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的准确率远比随机猜测(准确率10%)好，证明网络确实学到了东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  在GPU训练\n",
    "就像之前把Tensor从CPU转到GPU一样，模型也可以类似地从CPU转到GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3732)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "output = net(images)\n",
    "loss= criterion(output,labels)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果发现在GPU上并没有比CPU提速很多，实际上是因为网络比较小，GPU没有完全发挥自己的真正实力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对PyTorch的基础介绍至此结束。总结一下，本节主要包含以下内容。\n",
    "\n",
    "1. Tensor: 类似Numpy数组的数据结构，与Numpy接口类似，可方便地互相转换。\n",
    "2. autograd/: 为tensor提供自动求导功能。\n",
    "3. nn: 专门为神经网络设计的接口，提供了很多有用的功能(神经网络层，损失函数，优化器等)。\n",
    "4. 神经网络训练: 以CIFAR-10分类为例演示了神经网络的训练流程，包括数据加载、网络搭建、训练及测试。\n",
    "\n",
    "通过本节的学习，相信读者可以体会出PyTorch具有接口简单、使用灵活等特点。从下一章开始，本书将深入系统地讲解PyTorch的各部分知识。"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
